{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189c1345",
   "metadata": {},
   "source": [
    "# System Workflow\n",
    "\n",
    "![Screenshot](./Snapshots/flow_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d2f20",
   "metadata": {},
   "source": [
    "## Step-1 :\n",
    "## Load the Youtube Transcripts based on TimeStamp Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe9d613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader # Load the Youtube Transcript\n",
    "from langchain_community.document_loaders.youtube import TranscriptFormat # To Get transcripts as timestamped chunks\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c41f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 52 transcript chunks\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    loader = YoutubeLoader.from_youtube_url(\n",
    "        \"https://www.youtube.com/watch?v=pJdMxwXBsk0&list=PLKnIA16_RmvaTbihpo4MtzVm4XOQa0ER0&index=15\",\n",
    "         language=[\"hi\"],\n",
    "         translation=\"en\",\n",
    "        transcript_format=TranscriptFormat.CHUNKS,\n",
    "        chunk_size_seconds=60,\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    if docs:\n",
    "        print(f\"Successfully loaded {len(docs)} transcript chunks\")\n",
    "    else:\n",
    "        print(\"No transcript data was loaded (empty result)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YouTube transcript: {str(e)}\")\n",
    "    docs = None  \n",
    "\n",
    "if docs:\n",
    "    pass\n",
    "else:\n",
    "    print(\"Failed to load transcript, cannot proceed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2827201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deab689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b6c89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73493711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n",
      "Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\n"
     ]
    }
   ],
   "source": [
    "index= 0\n",
    "print(docs[index].metadata)\n",
    "print(docs[index].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6696921e",
   "metadata": {},
   "source": [
    "## Step-2\n",
    "## Loading the embedding model and the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d8eaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd991188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prabal Kuinkel\\Desktop\\Youtube-Conversational_AI\\youtube_ai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-mpnet-base-v2\")\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "from transformers import AutoTokenizer\n",
    "# Initialize a llm model\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# First load the tokenizer explicitly\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id = repo_id,\n",
    "    temperature = 0.8,\n",
    "    max_new_tokens=500,\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535bfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e7101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model_name = \"Llama-3.3-70b-Versatile\",max_tokens= 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82fda4",
   "metadata": {},
   "source": [
    "## Step-3\n",
    " \n",
    " ## Creating a vectordatabase using the Chroma db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc275395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store = FAISS.from_documents(docs, embedding_model)\n",
    "from langchain_chroma import Chroma\n",
    "vectorstore = Chroma.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1368eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-chroma\n",
    "# !pip install lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aafda84",
   "metadata": {},
   "source": [
    "## Step-4 Defining the retriever\n",
    "## Using the Metadatabased Filtering for retrievers\n",
    "\n",
    "#### -> this retriever is known as self-query retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af1fc675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[index].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "628aa3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The link of the video\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"start_seconds\",\n",
    "        description=\"The starting second of the video chunk (in seconds as integer)\",\n",
    "        type=\"integer\"  # Changed from string to integer\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"start_timestamp\",\n",
    "        description=\"Human-readable timestamp (HH:MM:SS format)\",\n",
    "        type=\"string\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88fc7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First get the base retriever from your vectorstore with increased k\n",
    "# base_vectorstore_retriever = vectorstore.as_retriever(\n",
    "#     # search_type = \"mmr\",\n",
    "#     search_kwargs={\"k\": 20,'lambda_mult':0.5}  # Increase this number as needed\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b5d503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Transcript of a youtube video\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    # base_retriever = base_vectorstore_retriever,\n",
    "    verbose=True,\n",
    "    search_kwargs={\"k\": 8}  # Increase this number as needed\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d00dbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='21e30dd3-44fe-41bf-ac33-736b4aeb985a', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=3060s', 'start_seconds': 3060, 'start_timestamp': '00:51:00'}, page_content='application.  Ok?  So with that I will conclude this video.  If you liked the video, please like it.  If you have not subscribed to this channel, please do subscribe.  See you in the next video , bye.'),\n",
       " Document(id='101ad05e-b3d5-42a8-9f4d-5f6f13fb6838', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\"),\n",
       " Document(id='01bd207a-d054-472c-9870-c3e77d17771b', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1320s', 'start_seconds': 1320, 'start_timestamp': '00:22:00'}, page_content=\"show you how to use advanced retrievers with your vector store, which will internally use very advanced search strategies to fetch relevant documents. So guys so far we have seen two retrievers which you can categorize on the basis of the document source that they are using.  Now we will look at some retrievers which you can differentiate on the basis of retrieval mechanism or retrieval strategy.  The first retriever among them that we are going to discuss is named MMR and its full form is Maximum Marginal Relevance.  Now what is this and how does it work?  Before that let me show you a problem many retrievers face.  Let's say you have this document source where you have a total of five documents stored in it.  Now if you pause the video and read these five documents, you will see that the documents here are around climate change,\"),\n",
       " Document(id='3430bf07-435f-4819-8c9b-1336da6823fa', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\"),\n",
       " Document(id='73d56729-0c4b-4279-80f7-51dddf2c6be7', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1440s', 'start_seconds': 1440, 'start_timestamp': '00:24:00'}, page_content='requested three results.  Here are your three results.  Document One has arrived.  This one, document two has also come, this one and document three has also come.  Because the relevance of these three was the highest.  Now what is the problem with these three results is that the first two results are saying exactly the same thing about glaciers are melting right and the third thing is talking about deforestation which is showing you a different perspective about climate change.  But the problem is that two out of three things are saying the same thing. What would have happened ideally?  It would have been better if we had shown these results where the first one would have been Document One, we would have fetched it, we would have talked about glacier melting, we would have brought D4 where we would have talked about wildfires, we would have talked about D5 where we would have talked about coastal cities getting submerged, here you are getting more'),\n",
       " Document(id='4633564d-c363-4eec-82f1-37b4f33456eb', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=660s', 'start_seconds': 660, 'start_timestamp': '00:11:00'}, page_content=\"a query example Albert Einstein It sends the query to Wikipedia API It retrieves the most relevant articles. Ok?  Now here retrieve means that internally there is some algorithm with the help of which it is being decided which is the most relevant document.  As much as I read about this particular retriever, it was written there that some keyword matching happens internally.  There is no synthetic search happening here.  A keyword based matching is being done and on the basis of the number of keywords matching it is being decided which is the most relevant document.  And then as that is being disassembled, you turn around and get those documents in the form of Langchain Document Objects.  So, there is not much special to teach here.  What I can do is I can show you a demonstration of how you can use this particular retriever.  So in today's video, I will show you all the code by writing it in Google Collab Notebook.\"),\n",
       " Document(id='c19bb531-eb54-43a5-aaf1-10df218f9ce4', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1080s', 'start_seconds': 1080, 'start_timestamp': '00:18:00'}, page_content='vectors are forming.  And here we have created the collection form as we did in the last video.  Ok?  And we ran it.  Now once your vector store is formed, you can form a retriever with the help of the vector store. So vector store dot edge retriever function is to create a retriever vector store retriever.  Ok? All you have to do here is tell how many relevant results you want back.  So we set the value of K to two and we have formed a retriever object.  Ok? In this step.  What are we doing now?  Writing a query. Like the query is what is chroma used for.  what shall we do now?   We will call the retriever.invoke function and we will pass this query.  Now what will happen behind the scenes?  This retriever will go.  This will convert this query into a vector.   It will perform a semantic search and'),\n",
       " Document(id='9df4d0ae-bf73-4dab-9f4b-2f161ffe834e', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1140s', 'start_seconds': 1140, 'start_timestamp': '00:19:00'}, page_content='bring you the top two results in document object format and store it in a result variable.  Ok?  And the rest of the code is the same.  I just ran a loop to print those results.  So you can see I asked for two results.  So since there is only one document about chroma here, it comes on top.  But since then another result had to be given to him.  So next he again selected this document. Ok?  But you get the idea.  Ok ?  Now here I had a doubt which I will share with you.  Maybe you too might be having that doubt.  This doubt may come to your mind that the work that we just did with the help of a retriever, in the previous video, we had got this work done directly from the Vector Store, if you remember. So what I can do is instead of making this retriever, I can write this code directly also. Vector store dot similarity')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example only specifies a filter\n",
    "retriever.invoke(\"Create me a blog post about the video.\")\n",
    "# retriever.invoke(\"what is meant by multi query retriever ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366c14f",
   "metadata": {},
   "source": [
    "## Step 5 Creating a Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af3d494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34025f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    template = \"\"\"You are an AI assistant , which has access to a youtubes video transcript. Answer the user's query based on the provided transcripts context and do not hallicunate. \n",
    "    If the answer to the user'query is not mentioned in the context or incase if you dont know the answer respond with 'Sorry i do not have answer to your question'.\n",
    "    'context'\n",
    "    {context}\n",
    "    'Question'\n",
    "    {input}\"\"\",\n",
    "    input_variables=['context','input']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854843a7",
   "metadata": {},
   "source": [
    "## Step-6 Creating a RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08b7ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain #\"Formats retrieved documents + question into a prompt and passes it to the LLM for answering.\"\n",
    "from langchain.chains import create_retrieval_chain # \"Combines a retriever (to fetch docs) with the 'create_stuff_document_chain' to automate end-to-end retrieval + answering.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c9987d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_docs_chain = create_stuff_documents_chain(llm=llm,prompt=template)\n",
    "rag_chain = create_retrieval_chain(retriever,combined_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7e2a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=rag_chain.invoke({\n",
    "    'input':\"Create me a blog post about the video.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ae02a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video discusses the importance of retrievers in Langchain, a language model framework. The speaker explains that a retriever is a component that fetches relevant documents from a data source in response to a user's query. They then delve into the different types of retrievers, including the Wikipedia Retriever, Multi-Query Retriever, and Contextual Compression Retriever.\n",
      "\n",
      "The Wikipedia Retriever is described as a retriever that queries the Wikipedia API to fetch relevant content for a given query. The speaker provides an example of how this retriever works, using a query about Albert Einstein. They explain that the retriever hits the Wikipedia API, retrieves the most relevant articles, and returns them in the format of Langchain Document Objects.\n",
      "\n",
      "The speaker also discusses the Multi-Query Retriever, which understands the context of the query and returns relevant documents based on that context. They provide an example of how this retriever works, using a query that has multiple possible interpretations. The Multi-Query Retriever is able to understand the ambiguity in the query and return results that are relevant to the intended topic.\n",
      "\n",
      "Additionally, the speaker mentions the Contextual Compression Retriever, but does not provide a detailed explanation of how it works. They also touch on the concept of Maximum Marginal Relevance (MMR), which is an algorithm designed to reduce redundancy in search results. MMR aims to return results that are not only relevant to the query but also diverse and non-redundant.\n",
      "\n",
      "The speaker also provides a demonstration of how to use the Multi-Query Retriever in a Google Collab Notebook, showing how to create a retriever and fetch relevant documents.\n",
      "\n",
      "Overall, the video provides an overview of the different types of retrievers in Langchain and how they can be used to fetch relevant documents from a data source. The speaker provides examples and demonstrations to illustrate how these retrievers work, and discusses the importance of diversity and non-redundancy in search results.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
