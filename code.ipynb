{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d37f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet youtube-transcript-api langchain_community\n",
    "# !pip install pytube\n",
    "# !pip install langchain_huggingface\n",
    "# !pip install -qU faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d2f20",
   "metadata": {},
   "source": [
    "## Step-1 :\n",
    "## Load the Youtube Transcripts based on TimeStamp Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe9d613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader # Load the Youtube Transcript\n",
    "from langchain_community.document_loaders.youtube import TranscriptFormat # To Get transcripts as timestamped chunks\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c41f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 52 transcript chunks\n",
      "First chunk content: Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic...\n",
      "First chunk metadata: {'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    loader = YoutubeLoader.from_youtube_url(\n",
    "        \"https://www.youtube.com/watch?v=pJdMxwXBsk0&list=PLKnIA16_RmvaTbihpo4MtzVm4XOQa0ER0&index=15\",\n",
    "         language=[\"hi\"],\n",
    "         translation=\"en\",\n",
    "        transcript_format=TranscriptFormat.CHUNKS,\n",
    "        chunk_size_seconds=60,\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    if docs:\n",
    "        print(f\"Successfully loaded {len(docs)} transcript chunks\")\n",
    "        print(f\"First chunk content: {docs[0].page_content[:200]}...\")  # Show first 200 chars\n",
    "        print(f\"First chunk metadata: {docs[0].metadata}\")\n",
    "    else:\n",
    "        print(\"No transcript data was loaded (empty result)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YouTube transcript: {str(e)}\")\n",
    "    docs = None  # or [] if you prefer an empty list instead of None\n",
    "\n",
    "# You can now check if docs exists before proceeding\n",
    "if docs:\n",
    "    # Continue with your processing\n",
    "    pass\n",
    "else:\n",
    "    print(\"Failed to load transcript, cannot proceed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2827201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deab689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b6c89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73493711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n",
      "Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\n"
     ]
    }
   ],
   "source": [
    "index= 0\n",
    "print(docs[index].metadata)\n",
    "print(docs[index].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6696921e",
   "metadata": {},
   "source": [
    "## Step-2\n",
    "## Loading the embedding model and the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d8eaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd991188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prabal Kuinkel\\Desktop\\Youtube-Conversational_AI\\youtube_ai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-mpnet-base-v2\")\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "from transformers import AutoTokenizer\n",
    "# Initialize a llm model\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# First load the tokenizer explicitly\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id = repo_id,\n",
    "    temperature = 0.8,\n",
    "    max_new_tokens=500,\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "535bfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9e7101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model_name = \"Llama-3.3-70b-Versatile\",max_tokens= 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82fda4",
   "metadata": {},
   "source": [
    "## Step-3\n",
    " \n",
    " ## Creating a vectordatabase using the Chroma db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc275395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store = FAISS.from_documents(docs, embedding_model)\n",
    "from langchain_chroma import Chroma\n",
    "vectorstore = Chroma.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa1368eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-chroma\n",
    "# !pip install lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aafda84",
   "metadata": {},
   "source": [
    "## Step-4 Defining the retriever\n",
    "## Using the Metadatabased Filtering for retrievers\n",
    "\n",
    "#### -> this retriever is known as self-query retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af1fc675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[index].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628aa3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The link of the video\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"start_seconds\",\n",
    "        description=\"The starting second of the video chunk (in seconds as integer)\",\n",
    "        type=\"integer\"  # Changed from string to integer\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"start_timestamp\",\n",
    "        description=\"Human-readable timestamp (HH:MM:SS format)\",\n",
    "        type=\"string\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First get the base retriever from your vectorstore with increased k\n",
    "# base_vectorstore_retriever = vectorstore.as_retriever(\n",
    "#     # search_type = \"mmr\",\n",
    "#     search_kwargs={\"k\": 20,'lambda_mult':0.5}  # Increase this number as needed\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b5d503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Transcript of a youtube video\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    # base_retriever = base_vectorstore_retriever,\n",
    "    verbose=True,\n",
    "    search_kwargs={\"k\": 8}  # Increase this number as needed\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d00dbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='ca167079-0ec5-4f74-8cc9-cca59cc4ee33', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=3060s', 'start_seconds': 3060, 'start_timestamp': '00:51:00'}, page_content='application.  Ok?  So with that I will conclude this video.  If you liked the video, please like it.  If you have not subscribed to this channel, please do subscribe.  See you in the next video , bye.'),\n",
       " Document(id='60f6adc0-1eb7-47b8-82a7-688339c7a742', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\"),\n",
       " Document(id='5a14e7a3-a612-4eb0-b343-03ef6da42cb2', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1320s', 'start_seconds': 1320, 'start_timestamp': '00:22:00'}, page_content=\"show you how to use advanced retrievers with your vector store, which will internally use very advanced search strategies to fetch relevant documents. So guys so far we have seen two retrievers which you can categorize on the basis of the document source that they are using.  Now we will look at some retrievers which you can differentiate on the basis of retrieval mechanism or retrieval strategy.  The first retriever among them that we are going to discuss is named MMR and its full form is Maximum Marginal Relevance.  Now what is this and how does it work?  Before that let me show you a problem many retrievers face.  Let's say you have this document source where you have a total of five documents stored in it.  Now if you pause the video and read these five documents, you will see that the documents here are around climate change,\"),\n",
       " Document(id='5ef4eded-c07a-4f65-94e1-4ad7bac119e0', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1080s', 'start_seconds': 1080, 'start_timestamp': '00:18:00'}, page_content='vectors are forming.  And here we have created the collection form as we did in the last video.  Ok?  And we ran it.  Now once your vector store is formed, you can form a retriever with the help of the vector store. So vector store dot edge retriever function is to create a retriever vector store retriever.  Ok? All you have to do here is tell how many relevant results you want back.  So we set the value of K to two and we have formed a retriever object.  Ok? In this step.  What are we doing now?  Writing a query. Like the query is what is chroma used for.  what shall we do now?   We will call the retriever.invoke function and we will pass this query.  Now what will happen behind the scenes?  This retriever will go.  This will convert this query into a vector.   It will perform a semantic search and'),\n",
       " Document(id='22a81ff5-0ae6-481c-9942-2fe055ce9517', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1440s', 'start_seconds': 1440, 'start_timestamp': '00:24:00'}, page_content='requested three results.  Here are your three results.  Document One has arrived.  This one, document two has also come, this one and document three has also come.  Because the relevance of these three was the highest.  Now what is the problem with these three results is that the first two results are saying exactly the same thing about glaciers are melting right and the third thing is talking about deforestation which is showing you a different perspective about climate change.  But the problem is that two out of three things are saying the same thing. What would have happened ideally?  It would have been better if we had shown these results where the first one would have been Document One, we would have fetched it, we would have talked about glacier melting, we would have brought D4 where we would have talked about wildfires, we would have talked about D5 where we would have talked about coastal cities getting submerged, here you are getting more'),\n",
       " Document(id='5b24dde7-d24b-4ed7-ba1f-562077ebd5cc', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1140s', 'start_seconds': 1140, 'start_timestamp': '00:19:00'}, page_content='bring you the top two results in document object format and store it in a result variable.  Ok?  And the rest of the code is the same.  I just ran a loop to print those results.  So you can see I asked for two results.  So since there is only one document about chroma here, it comes on top.  But since then another result had to be given to him.  So next he again selected this document. Ok?  But you get the idea.  Ok ?  Now here I had a doubt which I will share with you.  Maybe you too might be having that doubt.  This doubt may come to your mind that the work that we just did with the help of a retriever, in the previous video, we had got this work done directly from the Vector Store, if you remember. So what I can do is instead of making this retriever, I can write this code directly also. Vector store dot similarity'),\n",
       " Document(id='a1266fce-8673-430c-9613-7831bad4e516', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\"),\n",
       " Document(id='651fc716-a26d-43b1-8849-04014eb97ef6', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2820s', 'start_seconds': 2820, 'start_timestamp': '00:47:00'}, page_content='enter your model here.  Ok?  And in this step we have formed our retriever.  Now suppose our question is what is photosynthesis?  what did we do? Called CompressionRetriever.invoke and passed our query which in turn gave us the results and now we are printing the results. And you can see guys here are our results.  You will notice that even though all of our documents are one paragraph long, the answers we are getting back are very short one sentence answers.  Because only one line exists around photosynthesis in our documents.  And the same line is being extracted and shown to you. Apart from this, you will not see any sentence about Grand Canyon, Basketball etc. here.  Because all this work is being done behind the scenes by the Contextual Compression Retriever.  Ok? So I hope you understood how this particular retriever works.  Now before ending the video I')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example only specifies a filter\n",
    "retriever.invoke(\"Explain me in short the summary of the video ?\")\n",
    "# retriever.invoke(\"what is meant by multi query retriever ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366c14f",
   "metadata": {},
   "source": [
    "## Step 5 Creating a rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d494f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
