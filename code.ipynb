{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189c1345",
   "metadata": {},
   "source": [
    "# System Workflow\n",
    "\n",
    "![Screenshot](./Snapshots/flow_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d2f20",
   "metadata": {},
   "source": [
    "## Step-1 :\n",
    "## Load the Youtube Transcripts based on TimeStamp Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe9d613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader # Load the Youtube Transcript\n",
    "from langchain_community.document_loaders.youtube import TranscriptFormat # To Get transcripts as timestamped chunks\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c41f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 60 transcript chunks\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    loader = YoutubeLoader.from_youtube_url(\n",
    "        \"https://www.youtube.com/watch?v=LLEc_fqEk_k&t=1554s\",\n",
    "         language=[\"hi\"],\n",
    "         translation=\"en\",\n",
    "        transcript_format=TranscriptFormat.CHUNKS,\n",
    "        chunk_size_seconds=60,\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    if docs:\n",
    "        print(f\"Successfully loaded {len(docs)} transcript chunks\")\n",
    "    else:\n",
    "        print(\"No transcript data was loaded (empty result)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YouTube transcript: {str(e)}\")\n",
    "    docs = None  \n",
    "\n",
    "if docs:\n",
    "    pass\n",
    "else:\n",
    "    print(\"Failed to load transcript, cannot proceed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2827201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deab689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.youtube.com/watch?v=LLEc_fqEk_k&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Tarak Mehta Ka Ooltah Chashma Papa it is getting very late.  Brother brother brother brother tapora show the report cut wait hey. Ke papa's stop the knife, hey stop if not then Jetha ji hi baba oh\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b6c89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.youtube.com/watch?v=LLEc_fqEk_k&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"don't forget to have tea and breakfast before leaving.  If they go to the shop like this, then on an empty stomach, Natu Kaka, Baka Bhai and whoever they meet will keep on feeding them Badka the whole day. Yes brother, yes I am coming, go inside now. Yes Babita ji bye bye. And Babita ji, where are you jogging?  Yes.  By the way Jetha ji, you should also start regular jogging. Look, you ran so much and you were so half-fed.  Meaning you have no stamina at all.  If you do regular jogging then you will see that gradually your stamina will build up like this.  No, definitely, definitely.  I was going to start jogging in a day or two anyway. And I was going to ask you the secret of staying fit and healthy, which herbal thing do you eat? From the first time I saw you till today, you look the same.\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73493711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://www.youtube.com/watch?v=LLEc_fqEk_k&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n",
      "Tarak Mehta Ka Ooltah Chashma Papa it is getting very late.  Brother brother brother brother tapora show the report cut wait hey. Ke papa's stop the knife, hey stop if not then Jetha ji hi baba oh\n"
     ]
    }
   ],
   "source": [
    "index= 0\n",
    "print(docs[index].metadata)\n",
    "print(docs[index].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6696921e",
   "metadata": {},
   "source": [
    "## Step-2\n",
    "## Loading the embedding model and the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d8eaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd991188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prabal Kuinkel\\Desktop\\Youtube-Conversational_AI\\youtube_ai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-mpnet-base-v2\")\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "from transformers import AutoTokenizer\n",
    "# Initialize a llm model\n",
    "# repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# # First load the tokenizer explicitly\n",
    "# tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
    "# llm1 = HuggingFaceEndpoint(\n",
    "#     repo_id = repo_id,\n",
    "#     temperature = 0.8,\n",
    "#     max_new_tokens=500,\n",
    "# )\n",
    "# llm = ChatHuggingFace(llm=llm1,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535bfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e7101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model_name = \"Qwen-Qwq-32b\",max_tokens= 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82fda4",
   "metadata": {},
   "source": [
    "## Step-3\n",
    " \n",
    " ## Creating a vectordatabase using the Chroma db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc275395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store = FAISS.from_documents(docs, embedding_model)\n",
    "from langchain_chroma import Chroma\n",
    "vectorstore = Chroma.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1368eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-chroma\n",
    "# !pip install lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aafda84",
   "metadata": {},
   "source": [
    "## Step-4 Defining the retriever\n",
    "## Using the Metadatabased Filtering for retrievers\n",
    "\n",
    "#### -> this retriever is known as self-query retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af1fc675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://www.youtube.com/watch?v=LLEc_fqEk_k&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[index].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "628aa3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The link of the video\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"start_seconds\",\n",
    "        description=\"The starting second of the video chunk (in seconds as integer)\",\n",
    "        type=\"integer\"  # Changed from string to integer\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"start_timestamp\",\n",
    "        description=\"Human-readable timestamp (HH:MM:SS format)\",\n",
    "        type=\"string\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88fc7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First get the base retriever from your vectorstore with increased k\n",
    "# base_vectorstore_retriever = vectorstore.as_retriever(\n",
    "#     # search_type = \"mmr\",\n",
    "#     search_kwargs={\"k\": 20,'lambda_mult':0.5}  # Increase this number as needed\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b5d503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Transcript of a youtube video\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    # base_retriever = base_vectorstore_retriever,\n",
    "    verbose=True,\n",
    "    search_kwargs={\"k\": 5}  # Increase this number as needed\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d00dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example only specifies a filter\n",
    "# retriever.invoke(\"Create me a blog post about the video.\")\n",
    "# retriever.invoke(\"what is meant by multi query retriever ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7394ca0",
   "metadata": {},
   "source": [
    "## Step- 5 Creating tools\n",
    "\n",
    "### Tool A. VectorStore Retriever tool (Convert the rag_chain into a tool)\n",
    "Redirect to this tool if the user queries is regarding the Video content\n",
    "\n",
    "### Tool B. DuckDuckSeach Tool\n",
    "Redirect to this tool if the user query is general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f3bb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun #Search user queries Online\n",
    "\n",
    "@tool\n",
    "def retriever_vectorstore_tool(query:str)->str:\n",
    "    \"\"\"Use this tool when the user ask about:\n",
    "    - content of the youtube video\n",
    "    - Any queries specifically about the youtube video\n",
    "    Input should be the exact search query.\n",
    "    The tool will perform a vectorstore search using retriever.\"\"\"\n",
    "    return retriever.invoke(query)\n",
    "\n",
    "\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "@tool\n",
    "def duckducksearch_tool(query: str) -> str:\n",
    "    \"\"\"Use this tool when:\n",
    "    - The question is not about youtube video\n",
    "    \n",
    "    Input should be the exact search query.\n",
    "    The tool will perform a web search using DuckDuckGo.\n",
    "    \"\"\"\n",
    "    return search.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e1b58",
   "metadata": {},
   "source": [
    "## Step-6 Binding the llm with the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9144d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools= [retriever_vectorstore_tool,duckducksearch_tool]\n",
    "llm_with_tools=llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a3371",
   "metadata": {},
   "source": [
    "## Step-7 Define the langgraph workflow with memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68436115",
   "metadata": {},
   "source": [
    "### Step-7.1 Define the State (flow of information through nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88051b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated, TypedDict \n",
    "from typing import List \n",
    "from langchain_core.messages import AnyMessage #can be either HumanMsg or AImsg or ToolMsg\n",
    "from langgraph.graph.message import add_messages #Append the new messages insted of replacing\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"Represents the state of our graph\"\"\"\n",
    "    messages:Annotated[List[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7947b70",
   "metadata": {},
   "source": [
    "### Step-7.2 Define the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    " # ToolNode is pre-built component that will invoke/execute the tool in behalf of the user and returns the tool_response\n",
    " # tools_condition is pre-built component that routes to ToolNode if the last message has tool call , otherwise routes to end\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display #to visualize the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e1b6a4",
   "metadata": {},
   "source": [
    "#### Step- 7.2.1 \n",
    "#### Implement a ConversationalWindowBuffer Memory using langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that determines the best tool to server the user query \n",
    "def tool_calling_llm(State:State)->State:\n",
    "    return {'messages':llm_with_tools.invoke(State['messages'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4aa4b95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tools(tags=None, recurse=True, explode_args=False, func_accepts_config=True, func_accepts={'store': ('__pregel_store', None)}, tools_by_name={'retriever_vectorstore_tool': StructuredTool(name='retriever_vectorstore_tool', description='Use this tool when the user ask about:\\n    - content of the youtube video\\n    - Any queries specifically about the youtube video\\n    Input should be the exact search query.\\n    The tool will perform a vectorstore search using retriever.', args_schema=<class 'langchain_core.utils.pydantic.retriever_vectorstore_tool'>, func=<function retriever_vectorstore_tool at 0x0000018497A58FE0>), 'duckducksearch_tool': StructuredTool(name='duckducksearch_tool', description='Use this tool when:\\n    - The question is not about youtube video\\n\\n    Input should be the exact search query.\\n    The tool will perform a web search using DuckDuckGo.', args_schema=<class 'langchain_core.utils.pydantic.duckducksearch_tool'>, func=<function duckducksearch_tool at 0x000001849EF3E020>)}, tool_to_state_args={'retriever_vectorstore_tool': {}, 'duckducksearch_tool': {}}, tool_to_store_arg={'retriever_vectorstore_tool': None, 'duckducksearch_tool': None}, handle_tool_errors=True, messages_key='messages')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node = ToolNode(tools=tools)\n",
    "tool_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "423af05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initializing the StateGraph\n",
    "builder = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "#Adding the nodes\n",
    "builder.add_node('tool_calling_llm',tool_calling_llm) # returns the tools that is to be used\n",
    "builder.add_node('tools',tool_node) # Executes the specified tool\n",
    "\n",
    "#Adding Edges\n",
    "builder.add_edge(START,'tool_calling_llm')\n",
    "builder.add_conditional_edges(\n",
    "    'tool_calling_llm',\n",
    "    # If the latest message from AI is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message from AI is a not a tool call -> tools_condition routes to LLM, then generate final response and END\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge('tools','tool_calling_llm')\n",
    "\n",
    "#Compile the graph\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f46fd",
   "metadata": {},
   "source": [
    "### Code Explaination / Flow :\n",
    "\n",
    "    1. Starts with calling the 'tool_calling_llm' , which decides which tool is to be used to answer the user query .\n",
    "\n",
    "    2. It is redirected to the 'tools_condition' function , where \n",
    "        \n",
    "        Case I: If the Last 'AI Message' is a tool call ,then 'tools_conditions' automatically routes to 'tool_node' which will executes the specified tool and return the tool_response.\n",
    "\n",
    "        Case II: If the last 'AI Message' is not a tool call, then 'tools_conditions' routes to 'tool_calling_llm' generates the final reponse and route to END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b2c254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\n",
    "    'messages':\"What happened between minute 10 to 16 according to video?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "def081b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever.invoke(\"What are the names of footballers, mentioned according to the video , and can you also provide me the source/link of the video?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2614e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever.invoke(\"Who scored the goals according\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79a27982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What happened between minute 10 to 16 according to video?', additional_kwargs={}, response_metadata={}, id='23518801-770c-4063-bd0f-360bae6c8f3c'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aqvy', 'function': {'arguments': '{\"query\": \"What happened between minute 10 to 16 according to video?\"}', 'name': 'retriever_vectorstore_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 238, 'prompt_tokens': 303, 'total_tokens': 541, 'completion_time': 0.581416711, 'prompt_time': 0.017350453, 'queue_time': 0.491761932, 'total_time': 0.598767164}, 'model_name': 'Qwen-Qwq-32b', 'system_fingerprint': 'fp_3796682456', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8b1bb219-a78d-498a-aba3-5cff21340bdd-0', tool_calls=[{'name': 'retriever_vectorstore_tool', 'args': {'query': 'What happened between minute 10 to 16 according to video?'}, 'id': 'call_aqvy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 303, 'output_tokens': 238, 'total_tokens': 541}),\n",
       "  ToolMessage(content='Error: OutputParserException(\\'Parsing text\\\\n\\\\n<think>\\\\nOkay, let\\\\\\'s tackle this problem step by step. The user wants me to structure their query according to the given schema. First, I need to understand the data source provided. The data source here includes attributes like \"source\" (a string), \"start_seconds\" (an integer), and \"start_timestamp\" (a string in HH:MM:SS format). \\\\n\\\\nThe user\\\\\\'s query is asking, \"What happened between minute 10 to 16 according to video?\" So, I need to break this down into a query and filter. \\\\n\\\\nStarting with the query part: The actual content they\\\\\\'re interested in is the events between those minutes. Since the content is the transcript of the video, the query should probably be something like \"What happened\" to match the content, but maybe more specific. Alternatively, if the content is just the transcript text, maybe the query can be empty because the filter will handle the timing. Wait, looking back at example 2, when the query didn\\\\\\'t relate to existing attributes (like \"not published on Spotify\" which wasn\\\\\\'t an attribute), the filter was \"NO_FILTER\" and the query was empty. \\\\n\\\\nIn this case, the user is asking about a time range. The data source has \"start_seconds\" which is an integer. The question is between minute 10 to 16, so converting that to seconds: 10 minutes is 600 seconds, 16 minutes is 960 seconds. But since it\\\\\\'s \"between\", they probably want entries where start_seconds is greater than or equal to 600 and less than or equal to 960? Wait, but actually, if it\\\\\\'s \"between minute 10 to 16\", maybe it\\\\\\'s the duration from 10 to 16 minutes, so the start_seconds should be between 600 and 960. But I need to make sure that the comparison is correct. Since the attribute is \"start_seconds\", which is the starting point, so any entry that starts between those times. \\\\n\\\\nThe filter would need to use \"start_seconds\" with a \"gte\" (greater than or equal to 600) and \"lte\" (less than or equal to 960). But how to structure that. \\\\n\\\\nSo the filter should be: and(gte(start_seconds, 600), lte(start_seconds, 960)). Wait, but in the example, the format is comp(attr, val), so each comparison is like \"gte(\\\\\\\\\"start_seconds\\\\\\\\\", 600)\". Then combine those with \"and\".\\\\n\\\\nPutting that together, the filter would be \"and(gte(\\\\\\\\\"start_seconds\\\\\\\\\", 600), lte(\\\\\\\\\"start_seconds\\\\\\\\\", 960))\". \\\\n\\\\nThe query part should be the text part that matches the content. The user\\\\\\'s question is \"What happened between minute 10 to 16 according to video?\" The actual content is the transcript, so the query should probably be the text that\\\\\\'s in the transcript about what happened in that time. But since the time is handled by the filter, the query might be empty because the content itself (the transcript) doesn\\\\\\'t specifically mention the time in the text. Alternatively, maybe the query is \"What happened\" but that\\\\\\'s part of the question. The guidelines say the query should contain text to compare to document contents. The actual content here is the transcript, so if the user is asking for what happened in that time, the query might need to be an empty string because the time is handled via the filter, and the content is just the transcript\\\\\\'s text. \\\\n\\\\nWait, in Example 1, the query was \"teenager love\" which is the content part (the lyrics about teenage romance), and the filter handled the artists and genre. Similarly, here, the content is the transcript, so if the user is asking for events between 10-16 minutes, the actual content (transcript) doesn\\\\\\'t have that time info except via the attributes. Therefore, the query might be empty, or maybe \"What happened\" is part of the query. Wait, but according to the schema, the query is the text to compare to document contents. Since the content is the transcript\\\\\\'s text, the query should be the actual text they want to search. But the user\\\\\\'s question is about a time period, so the actual event details would be in the transcript\\\\\\'s text, but the time is an attribute. Therefore, the query might not have any specific text to search beyond the time filter. Therefore, the query could be an empty string, and the filter handles the timing. \\\\n\\\\nAlternatively, maybe \"What happened\" is part of the query. But I think the query should focus on the content\\\\\\'s text. Since the question is asking for events during that time, the actual content (transcript) would have\\\\n raised following error:\\\\nGot invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)\\\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \\\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \\')\\n Please fix your mistakes.', name='retriever_vectorstore_tool', id='ee152707-cf79-406d-bf9c-8b234c39852b', tool_call_id='call_aqvy', status='error'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fhms', 'function': {'arguments': '{\"query\": \"What happened between minute 10 to 16 according to video?\"}', 'name': 'retriever_vectorstore_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 285, 'prompt_tokens': 1496, 'total_tokens': 1781, 'completion_time': 0.701006023, 'prompt_time': 0.097406631, 'queue_time': 0.347539069, 'total_time': 0.798412654}, 'model_name': 'Qwen-Qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c1a599a0-3795-4c7a-92df-e90373bbaa7c-0', tool_calls=[{'name': 'retriever_vectorstore_tool', 'args': {'query': 'What happened between minute 10 to 16 according to video?'}, 'id': 'call_fhms', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1496, 'output_tokens': 285, 'total_tokens': 1781}),\n",
       "  ToolMessage(content='[Document(id=\\'6ee3379e-4c65-46d8-b575-a6bb45274271\\', metadata={\\'source\\': \\'https://www.youtube.com/watch?v=LLEc_fqEk_k&t=660s\\', \\'start_seconds\\': 660, \\'start_timestamp\\': \\'00:11:00\\'}, page_content=\"Sorry Ma\\'am come with me Let\\'s switch it off now Yes Ma\\'am We were just keeping it aside Come with me to the Principal\\'s office Ma\\'am Sorry Ma\\'am No Principal Ma\\'am Sorry Ma\\'am Sorry Come on Ma\\'am Sorry Come on Ma\\'am Sorry Ma\\'am Please Sorry Ma\\'am Please Ma\\'am R Sorry Ma\\'am Ma\\'am Please Ma\\'am Ma\\'am Please Ma\\'am Please Ma\\'am Ma\\'am Sorry Ma\\'am Sorry Ma\\'am Ma\\'am Hey Tappu After school gets over forward all your funny jokes to me Hey it seems you have n\\'t heard the notice regarding mobile that is read in every class right Sorry Ma\\'am And why are you guys standing come quickly I will come in Ma\\'am Yes come in come come and stand here come what happened\"), Document(id=\\'cc6bbf77-78fe-4122-a3ed-75e4cf33cb5a\\', metadata={\\'source\\': \\'https://www.youtube.com/watch?v=LLEc_fqEk_k&t=720s\\', \\'start_seconds\\': 720, \\'start_timestamp\\': \\'00:12:00\\'}, page_content=\"Leena It has not been even 2 minutes since the notice about mobile was heard and these people were reading jokes on their mobiles on the teachers.  Wow Tappu Sena, number one in good work, social work, mischief, fun and now jokes on teachers. Sorry ma\\'am.  Sorry ma\\'am.  No sorry Tapu.  Don\\'t think that you have done good social work. Therefore you will be forgiven for every mistake. Even if you do 100 good deeds, but if you make such a mistake, you will never be forgiven for such a mistake. By the way what is the joke Tappu read it?  Ma\\'am ma\\'am ma\\'am I\\'m really very sorry ma\\'am.  Read it.  Ma\\'am ma\\'am sorry ma\\'am.  Read it. From do s i.  Read it.\"), Document(id=\\'9864c4da-f252-418c-9910-9f4d8a92c6a0\\', metadata={\\'source\\': \\'https://www.youtube.com/watch?v=LLEc_fqEk_k&t=600s\\', \\'start_seconds\\': 600, \\'start_timestamp\\': \\'00:10:00\\'}, page_content=\"this joke, the teacher\\'s husband came home late, that is why the teacher punished her husband and made him stand like a rooster outside the house and said 100 times that he will not come home late. Ice Goli Tappu Stand up Ma\\'am Sorry Ma\\'am Sorry Sorry Ma\\'am Stand up Ma\\'am Sorry stand up\"), Document(id=\\'d3b870df-4c71-4cd3-9e56-72de27613f64\\', metadata={\\'source\\': \\'https://www.youtube.com/watch?v=LLEc_fqEk_k&t=840s\\', \\'start_seconds\\': 840, \\'start_timestamp\\': \\'00:14:00\\'}, page_content=\"So this is what you think about your teachers. No ma\\'am.  We respect teachers a lot. Yes ma\\'am.  These jokes came in the message. Please forgive us ma\\'am please. Sorry shut up.  If you respected the teacher and principal, you would not have switched on your mobile despite hearing the notice.  You people have made fun of the teacher.  You make fun of those teachers who are your gurus. All three of you will be punished for this. Ma\\'am, please call his parents. Why should we call their parents?   It is also the responsibility of parents to know what their children do and what they do not.  Parents give mobile phones to their children but do\"), Document(id=\\'21bd6037-2eca-4758-afa9-6eda387fe895\\', metadata={\\'source\\': \\'https://www.youtube.com/watch?v=LLEc_fqEk_k&t=900s\\', \\'start_seconds\\': 900, \\'start_timestamp\\': \\'00:15:00\\'}, page_content=\"not teach them when and how to use them.  Now these people themselves will tell their parents that they have been expelled from school. Ma\\'am Ma\\'am such mistake will not be repeated Ma\\'am sorry Ma\\'am please Ma\\'am I do n\\'t want any argument Ma\\'am I don\\'t want to hear anything You all go home and come back only after bringing your parents and then we will see what to do next regarding your punishment.  Right now you all go home right now and Leena confiscate their mobiles right now.  Ok ma\\'am bring the mobile. Ma\\'am please don\\'t, ma\\'am please take your bag\")]', name='retriever_vectorstore_tool', id='ce299774-1a6c-4c3b-94f1-c0036d4fee3b', tool_call_id='call_fhms'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1000, 'prompt_tokens': 2654, 'total_tokens': 3654, 'completion_time': 2.267435828, 'prompt_time': 0.141432997, 'queue_time': 0.272019061, 'total_time': 2.408868825}, 'model_name': 'Qwen-Qwq-32b', 'system_fingerprint': 'fp_fbb7e6cc39', 'finish_reason': 'length', 'logprobs': None}, id='run-be749f8c-d862-4920-9200-e4ca1a3782e8-0', usage_metadata={'input_tokens': 2654, 'output_tokens': 1000, 'total_tokens': 3654})]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8687288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
