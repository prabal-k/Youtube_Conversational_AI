{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189c1345",
   "metadata": {},
   "source": [
    "# System Workflow\n",
    "\n",
    "![Screenshot](./Snapshots/flow_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d2f20",
   "metadata": {},
   "source": [
    "## Step-1 :\n",
    "## Load the Youtube Transcripts based on TimeStamp Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe9d613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader # Load the Youtube Transcript\n",
    "from langchain_community.document_loaders.youtube import TranscriptFormat # To Get transcripts as timestamped chunks\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c41f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 52 transcript chunks\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    loader = YoutubeLoader.from_youtube_url(\n",
    "        \"https://www.youtube.com/watch?v=pJdMxwXBsk0&list=PLKnIA16_RmvaTbihpo4MtzVm4XOQa0ER0&index=15\",\n",
    "         language=[\"hi\"],\n",
    "         translation=\"en\",\n",
    "        transcript_format=TranscriptFormat.CHUNKS,\n",
    "        chunk_size_seconds=60,\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    if docs:\n",
    "        print(f\"Successfully loaded {len(docs)} transcript chunks\")\n",
    "    else:\n",
    "        print(\"No transcript data was loaded (empty result)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YouTube transcript: {str(e)}\")\n",
    "    docs = None  \n",
    "\n",
    "if docs:\n",
    "    pass\n",
    "else:\n",
    "    print(\"Failed to load transcript, cannot proceed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2827201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deab689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b6c89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73493711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n",
      "Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\n"
     ]
    }
   ],
   "source": [
    "index= 0\n",
    "print(docs[index].metadata)\n",
    "print(docs[index].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6696921e",
   "metadata": {},
   "source": [
    "## Step-2\n",
    "## Loading the embedding model and the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d8eaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd991188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prabal Kuinkel\\Desktop\\Youtube-Conversational_AI\\youtube_ai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-mpnet-base-v2\")\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "from transformers import AutoTokenizer\n",
    "# Initialize a llm model\n",
    "# repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# # First load the tokenizer explicitly\n",
    "# tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
    "# llm1 = HuggingFaceEndpoint(\n",
    "#     repo_id = repo_id,\n",
    "#     temperature = 0.8,\n",
    "#     max_new_tokens=500,\n",
    "# )\n",
    "# llm = ChatHuggingFace(llm=llm1,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535bfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e7101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model_name = \"Llama-3.3-70b-Versatile\",max_tokens= 900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82fda4",
   "metadata": {},
   "source": [
    "## Step-3\n",
    " \n",
    " ## Creating a vectordatabase using the Chroma db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc275395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store = FAISS.from_documents(docs, embedding_model)\n",
    "from langchain_chroma import Chroma\n",
    "vectorstore = Chroma.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1368eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-chroma\n",
    "# !pip install lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aafda84",
   "metadata": {},
   "source": [
    "## Step-4 Defining the retriever\n",
    "## Using the Metadatabased Filtering for retrievers\n",
    "\n",
    "#### -> this retriever is known as self-query retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af1fc675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[index].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "628aa3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The link of the video\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"start_seconds\",\n",
    "        description=\"The starting second of the video chunk (in seconds as integer)\",\n",
    "        type=\"integer\"  # Changed from string to integer\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"start_timestamp\",\n",
    "        description=\"Human-readable timestamp (HH:MM:SS format)\",\n",
    "        type=\"string\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88fc7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First get the base retriever from your vectorstore with increased k\n",
    "# base_vectorstore_retriever = vectorstore.as_retriever(\n",
    "#     # search_type = \"mmr\",\n",
    "#     search_kwargs={\"k\": 20,'lambda_mult':0.5}  # Increase this number as needed\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b5d503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Transcript of a youtube video\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    # base_retriever = base_vectorstore_retriever,\n",
    "    verbose=True,\n",
    "    search_kwargs={\"k\": 8}  # Increase this number as needed\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d00dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example only specifies a filter\n",
    "# retriever.invoke(\"Create me a blog post about the video.\")\n",
    "# retriever.invoke(\"what is meant by multi query retriever ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366c14f",
   "metadata": {},
   "source": [
    "## Step 5 Creating a Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af3d494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34025f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    template = \"\"\"You are an AI assistant , which has access to a youtubes video transcript. Answer the user's query based on the provided transcripts context and do not hallicunate. \n",
    "    If the answer to the user'query is not mentioned in the context or incase if you dont know the answer respond with 'Sorry i do not have answer to your question'.\n",
    "    'context'\n",
    "    {context}\n",
    "    'Question'\n",
    "    {input}\"\"\",\n",
    "    input_variables=['context','input']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854843a7",
   "metadata": {},
   "source": [
    "## Step-6 Creating a RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08b7ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain #\"Formats retrieved documents + question into a prompt and passes it to the LLM for answering.\"\n",
    "from langchain.chains import create_retrieval_chain # \"Combines a retriever (to fetch docs) with the 'create_stuff_document_chain' to automate end-to-end retrieval + answering.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c9987d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_docs_chain = create_stuff_documents_chain(llm=llm,prompt=template)\n",
    "rag_chain = create_retrieval_chain(retriever,combined_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7e2a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result=rag_chain.invoke({\n",
    "#     'input':\"Create me a 8 MCQ questions from the video . Also provide 4 options and also tell which is the correct one .\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ae02a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7394ca0",
   "metadata": {},
   "source": [
    "## Step- 7 Creating tools\n",
    "\n",
    "### Tool A. VectorStore Retriever tool (Convert the rag_chain into a tool)\n",
    "Redirect to this tool if the user queries is regarding the Video content\n",
    "\n",
    "### Tool B. DuckDuckSeach Tool\n",
    "Redirect to this tool if the user query is general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f3bb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun #Search user queries Online\n",
    "\n",
    "@tool\n",
    "def retriever_vectorstore_tool(query:str)->str:\n",
    "    \"\"\"Use this tool when the user ask about:\n",
    "    - content of the youtube video\n",
    "    - Any queries specifically about the youtube video\n",
    "    Input should be the exact search query.\n",
    "    The tool will perform a vectorstore search using retriever.\"\"\"\n",
    "    # print(query)\n",
    "    docs = retriever.invoke(query)\n",
    "    print(f\"_______________Retrieved Context from vectorstore_____ {docs}\")\n",
    "    # return rag_chain.invoke({\"input\":query})\n",
    "    return docs\n",
    "\n",
    "\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "@tool\n",
    "def duckducksearch_tool(query: str) -> str:\n",
    "    \"\"\"Use this tool when:\n",
    "    - The question is not about youtube video\n",
    "    - The question requires current, real-world information\n",
    "    - The topic is general knowledge\n",
    "    - The query is about news, weather, or public information\n",
    "    \n",
    "    Input should be the exact search query.\n",
    "    The tool will perform a web search using DuckDuckGo.\n",
    "    \"\"\"\n",
    "    return search.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e1b58",
   "metadata": {},
   "source": [
    "## Step-8 Creating a react agent using langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad7b9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.prebuilt import create_react_agent\n",
    "from langchain.agents import AgentExecutor,create_react_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b24b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"\n",
    "# Answer the following questions as best you can. You have access to the following tools:\n",
    "# {tools}\n",
    "\n",
    "# Use the following format:\n",
    "\n",
    "# Question: the input question you must answer\n",
    "# Thought: you should always think about what to do\n",
    "# Action: the action to take, should be one of [{tool_names}]\n",
    "# Action Input: the input to the action\n",
    "# Observation: the result of the action\n",
    "# ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "# Thought: I now know the final answer\n",
    "# Final Answer: the final answer to the original input question\n",
    "\n",
    "# Begin!\n",
    "\n",
    "# Question: {input}\n",
    "# Thought:{agent_scratchpad}\n",
    "# \"\"\",\n",
    "# input_variables=['tools','tool_names','input','agent_scratchpad']\n",
    "# )\n",
    "# Step 2: Pull the ReAct prompt from LangChain Hub\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/react\")  # pulls the standard ReAct agent prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcfece67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = [retriever_vectorstore_tool,duckducksearch_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0534955a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='retriever_vectorstore_tool', description='Use this tool when the user ask about:\\n    - content of the youtube video\\n    - Any queries specifically about the youtube video\\n    Input should be the exact search query.\\n    The tool will perform a vectorstore search using retriever.', args_schema=<class 'langchain_core.utils.pydantic.retriever_vectorstore_tool'>, func=<function retriever_vectorstore_tool at 0x000002611C27F7E0>),\n",
       " StructuredTool(name='duckducksearch_tool', description='Use this tool when:\\n    - The question is not about youtube video\\n    - The question requires current, real-world information\\n    - The topic is general knowledge\\n    - The query is about news, weather, or public information\\n\\n    Input should be the exact search query.\\n    The tool will perform a web search using DuckDuckGo.', args_schema=<class 'langchain_core.utils.pydantic.duckducksearch_tool'>, func=<function duckducksearch_tool at 0x000002611C27F060>)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1047d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [retriever_vectorstore_tool,duckducksearch_tool]\n",
    "agent = create_react_agent(\n",
    "    llm=llm, \n",
    "    tools=[retriever_vectorstore_tool,duckducksearch_tool], \n",
    "    prompt=prompt)\n",
    "\n",
    "\n",
    "# Step 4: Wrap it with AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=[retriever_vectorstore_tool,duckducksearch_tool],\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c91c3ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo provide a detailed summary of the video, I first need to understand what the video is about. \n",
      "\n",
      "Action: retriever_vectorstore_tool\n",
      "Action Input: \"video summary\"\u001b[0m_______________Retrieved Context from vectorstore_____ [Document(id='bdf26d33-c0a0-4a5f-b4a5-2c7aac65d5c1', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=3060s', 'start_seconds': 3060, 'start_timestamp': '00:51:00'}, page_content='application.  Ok?  So with that I will conclude this video.  If you liked the video, please like it.  If you have not subscribed to this channel, please do subscribe.  See you in the next video , bye.'), Document(id='5924e11e-1fc0-41c5-9a3b-52d184620f08', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\"), Document(id='06c18baf-0711-421b-a53f-268da9fde7b8', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1320s', 'start_seconds': 1320, 'start_timestamp': '00:22:00'}, page_content=\"show you how to use advanced retrievers with your vector store, which will internally use very advanced search strategies to fetch relevant documents. So guys so far we have seen two retrievers which you can categorize on the basis of the document source that they are using.  Now we will look at some retrievers which you can differentiate on the basis of retrieval mechanism or retrieval strategy.  The first retriever among them that we are going to discuss is named MMR and its full form is Maximum Marginal Relevance.  Now what is this and how does it work?  Before that let me show you a problem many retrievers face.  Let's say you have this document source where you have a total of five documents stored in it.  Now if you pause the video and read these five documents, you will see that the documents here are around climate change,\"), Document(id='c6a5d955-1ba1-4411-bf85-16376c430421', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1140s', 'start_seconds': 1140, 'start_timestamp': '00:19:00'}, page_content='bring you the top two results in document object format and store it in a result variable.  Ok?  And the rest of the code is the same.  I just ran a loop to print those results.  So you can see I asked for two results.  So since there is only one document about chroma here, it comes on top.  But since then another result had to be given to him.  So next he again selected this document. Ok?  But you get the idea.  Ok ?  Now here I had a doubt which I will share with you.  Maybe you too might be having that doubt.  This doubt may come to your mind that the work that we just did with the help of a retriever, in the previous video, we had got this work done directly from the Vector Store, if you remember. So what I can do is instead of making this retriever, I can write this code directly also. Vector store dot similarity'), Document(id='7387208d-fc1d-4762-acee-58c6a1e3869c', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2760s', 'start_seconds': 2760, 'start_timestamp': '00:46:00'}, page_content=\"talking about photosynthesis again.  We are completely talking about basketball here. And here we are talking about cinema extras. Ok?  Now what are we doing here ?  First let's create a vector store. And the Vector store belongs to Fyers again. Here we are passing our documents. Passing our embedding models. Now what do we have to do in this step ?  We need to create our own contextual compression retriever. Before you build a Butt Contextual Compression Retriever, there are two things you need to know.  First what will be your base retriever?  So that's our base retriever.  We created a simple similarity search based retriever using the vector store.  Ok?  And second you have to make a compressor.  So what did we do here?  Created a compressor which is basically an LLM.  Ok ?  And we have a class called LLM Chain Extractor. With its help we are making this compressor. Ok?  You can use this code as it is. You just have to\"), Document(id='68c536f4-0ed6-438f-af06-5ca0bfb47955', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1440s', 'start_seconds': 1440, 'start_timestamp': '00:24:00'}, page_content='requested three results.  Here are your three results.  Document One has arrived.  This one, document two has also come, this one and document three has also come.  Because the relevance of these three was the highest.  Now what is the problem with these three results is that the first two results are saying exactly the same thing about glaciers are melting right and the third thing is talking about deforestation which is showing you a different perspective about climate change.  But the problem is that two out of three things are saying the same thing. What would have happened ideally?  It would have been better if we had shown these results where the first one would have been Document One, we would have fetched it, we would have talked about glacier melting, we would have brought D4 where we would have talked about wildfires, we would have talked about D5 where we would have talked about coastal cities getting submerged, here you are getting more'), Document(id='fa5b1fa2-554a-4e1f-9945-03af9f98a060', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2820s', 'start_seconds': 2820, 'start_timestamp': '00:47:00'}, page_content='enter your model here.  Ok?  And in this step we have formed our retriever.  Now suppose our question is what is photosynthesis?  what did we do? Called CompressionRetriever.invoke and passed our query which in turn gave us the results and now we are printing the results. And you can see guys here are our results.  You will notice that even though all of our documents are one paragraph long, the answers we are getting back are very short one sentence answers.  Because only one line exists around photosynthesis in our documents.  And the same line is being extracted and shown to you. Apart from this, you will not see any sentence about Grand Canyon, Basketball etc. here.  Because all this work is being done behind the scenes by the Contextual Compression Retriever.  Ok? So I hope you understood how this particular retriever works.  Now before ending the video I'), Document(id='bfd40b71-0d54-4c97-bd54-d984cf4a0d8d', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1080s', 'start_seconds': 1080, 'start_timestamp': '00:18:00'}, page_content='vectors are forming.  And here we have created the collection form as we did in the last video.  Ok?  And we ran it.  Now once your vector store is formed, you can form a retriever with the help of the vector store. So vector store dot edge retriever function is to create a retriever vector store retriever.  Ok? All you have to do here is tell how many relevant results you want back.  So we set the value of K to two and we have formed a retriever object.  Ok? In this step.  What are we doing now?  Writing a query. Like the query is what is chroma used for.  what shall we do now?   We will call the retriever.invoke function and we will pass this query.  Now what will happen behind the scenes?  This retriever will go.  This will convert this query into a vector.   It will perform a semantic search and')]\n",
      "\u001b[36;1m\u001b[1;3m[Document(id='bdf26d33-c0a0-4a5f-b4a5-2c7aac65d5c1', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=3060s', 'start_seconds': 3060, 'start_timestamp': '00:51:00'}, page_content='application.  Ok?  So with that I will conclude this video.  If you liked the video, please like it.  If you have not subscribed to this channel, please do subscribe.  See you in the next video , bye.'), Document(id='5924e11e-1fc0-41c5-9a3b-52d184620f08', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\"), Document(id='06c18baf-0711-421b-a53f-268da9fde7b8', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1320s', 'start_seconds': 1320, 'start_timestamp': '00:22:00'}, page_content=\"show you how to use advanced retrievers with your vector store, which will internally use very advanced search strategies to fetch relevant documents. So guys so far we have seen two retrievers which you can categorize on the basis of the document source that they are using.  Now we will look at some retrievers which you can differentiate on the basis of retrieval mechanism or retrieval strategy.  The first retriever among them that we are going to discuss is named MMR and its full form is Maximum Marginal Relevance.  Now what is this and how does it work?  Before that let me show you a problem many retrievers face.  Let's say you have this document source where you have a total of five documents stored in it.  Now if you pause the video and read these five documents, you will see that the documents here are around climate change,\"), Document(id='c6a5d955-1ba1-4411-bf85-16376c430421', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1140s', 'start_seconds': 1140, 'start_timestamp': '00:19:00'}, page_content='bring you the top two results in document object format and store it in a result variable.  Ok?  And the rest of the code is the same.  I just ran a loop to print those results.  So you can see I asked for two results.  So since there is only one document about chroma here, it comes on top.  But since then another result had to be given to him.  So next he again selected this document. Ok?  But you get the idea.  Ok ?  Now here I had a doubt which I will share with you.  Maybe you too might be having that doubt.  This doubt may come to your mind that the work that we just did with the help of a retriever, in the previous video, we had got this work done directly from the Vector Store, if you remember. So what I can do is instead of making this retriever, I can write this code directly also. Vector store dot similarity'), Document(id='7387208d-fc1d-4762-acee-58c6a1e3869c', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2760s', 'start_seconds': 2760, 'start_timestamp': '00:46:00'}, page_content=\"talking about photosynthesis again.  We are completely talking about basketball here. And here we are talking about cinema extras. Ok?  Now what are we doing here ?  First let's create a vector store. And the Vector store belongs to Fyers again. Here we are passing our documents. Passing our embedding models. Now what do we have to do in this step ?  We need to create our own contextual compression retriever. Before you build a Butt Contextual Compression Retriever, there are two things you need to know.  First what will be your base retriever?  So that's our base retriever.  We created a simple similarity search based retriever using the vector store.  Ok?  And second you have to make a compressor.  So what did we do here?  Created a compressor which is basically an LLM.  Ok ?  And we have a class called LLM Chain Extractor. With its help we are making this compressor. Ok?  You can use this code as it is. You just have to\"), Document(id='68c536f4-0ed6-438f-af06-5ca0bfb47955', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1440s', 'start_seconds': 1440, 'start_timestamp': '00:24:00'}, page_content='requested three results.  Here are your three results.  Document One has arrived.  This one, document two has also come, this one and document three has also come.  Because the relevance of these three was the highest.  Now what is the problem with these three results is that the first two results are saying exactly the same thing about glaciers are melting right and the third thing is talking about deforestation which is showing you a different perspective about climate change.  But the problem is that two out of three things are saying the same thing. What would have happened ideally?  It would have been better if we had shown these results where the first one would have been Document One, we would have fetched it, we would have talked about glacier melting, we would have brought D4 where we would have talked about wildfires, we would have talked about D5 where we would have talked about coastal cities getting submerged, here you are getting more'), Document(id='fa5b1fa2-554a-4e1f-9945-03af9f98a060', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2820s', 'start_seconds': 2820, 'start_timestamp': '00:47:00'}, page_content='enter your model here.  Ok?  And in this step we have formed our retriever.  Now suppose our question is what is photosynthesis?  what did we do? Called CompressionRetriever.invoke and passed our query which in turn gave us the results and now we are printing the results. And you can see guys here are our results.  You will notice that even though all of our documents are one paragraph long, the answers we are getting back are very short one sentence answers.  Because only one line exists around photosynthesis in our documents.  And the same line is being extracted and shown to you. Apart from this, you will not see any sentence about Grand Canyon, Basketball etc. here.  Because all this work is being done behind the scenes by the Contextual Compression Retriever.  Ok? So I hope you understood how this particular retriever works.  Now before ending the video I'), Document(id='bfd40b71-0d54-4c97-bd54-d984cf4a0d8d', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1080s', 'start_seconds': 1080, 'start_timestamp': '00:18:00'}, page_content='vectors are forming.  And here we have created the collection form as we did in the last video.  Ok?  And we ran it.  Now once your vector store is formed, you can form a retriever with the help of the vector store. So vector store dot edge retriever function is to create a retriever vector store retriever.  Ok? All you have to do here is tell how many relevant results you want back.  So we set the value of K to two and we have formed a retriever object.  Ok? In this step.  What are we doing now?  Writing a query. Like the query is what is chroma used for.  what shall we do now?   We will call the retriever.invoke function and we will pass this query.  Now what will happen behind the scenes?  This retriever will go.  This will convert this query into a vector.   It will perform a semantic search and')]\u001b[0m\u001b[32;1m\u001b[1;3mThe video appears to be about retrievers in the context of language models and vector stores. \n",
      "\n",
      "Action: retriever_vectorstore_tool\n",
      "Action Input: \"video summary retrievers\"\u001b[0m_______________Retrieved Context from vectorstore_____ [Document(id='06c18baf-0711-421b-a53f-268da9fde7b8', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1320s', 'start_seconds': 1320, 'start_timestamp': '00:22:00'}, page_content=\"show you how to use advanced retrievers with your vector store, which will internally use very advanced search strategies to fetch relevant documents. So guys so far we have seen two retrievers which you can categorize on the basis of the document source that they are using.  Now we will look at some retrievers which you can differentiate on the basis of retrieval mechanism or retrieval strategy.  The first retriever among them that we are going to discuss is named MMR and its full form is Maximum Marginal Relevance.  Now what is this and how does it work?  Before that let me show you a problem many retrievers face.  Let's say you have this document source where you have a total of five documents stored in it.  Now if you pause the video and read these five documents, you will see that the documents here are around climate change,\"), Document(id='7387208d-fc1d-4762-acee-58c6a1e3869c', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2760s', 'start_seconds': 2760, 'start_timestamp': '00:46:00'}, page_content=\"talking about photosynthesis again.  We are completely talking about basketball here. And here we are talking about cinema extras. Ok?  Now what are we doing here ?  First let's create a vector store. And the Vector store belongs to Fyers again. Here we are passing our documents. Passing our embedding models. Now what do we have to do in this step ?  We need to create our own contextual compression retriever. Before you build a Butt Contextual Compression Retriever, there are two things you need to know.  First what will be your base retriever?  So that's our base retriever.  We created a simple similarity search based retriever using the vector store.  Ok?  And second you have to make a compressor.  So what did we do here?  Created a compressor which is basically an LLM.  Ok ?  And we have a class called LLM Chain Extractor. With its help we are making this compressor. Ok?  You can use this code as it is. You just have to\"), Document(id='f429a961-537f-4600-889b-f9c9be84dcfa', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2880s', 'start_seconds': 2880, 'start_timestamp': '00:48:00'}, page_content='would like to discuss one more thing with you that apart from the retrievers that we have read about till now, there are many other retrievers that exist.  Such as Parent Document Retriever, Time Weighted Vector Retriever, Self Query Retriever, OnSumable Retriever, Multi Retriever and so on.  If you want to know more about any of these retrievers or if you need it in your project then you can visit this particular link. I will give it to you in the description of the video. All the Retrievers available in Lang Chen are provided to you here. You can click on any of these and see how that particular retriever works.  You will get sample code and its description all at one place. Obviously it is not possible to cover all these retrievers. Going forward, when we create projects etc., if we need any particular retriever then I will definitely read it to you.  But covering everything did'), Document(id='9535fc07-6c02-477c-afb6-c1fd24cf8e34', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=540s', 'start_seconds': 540, 'start_timestamp': '00:09:00'}, page_content=\"retrievers.  So now what do I do first?  I will give you a little flavour of the different categories based on the data source and then after that I will give you a little flavour of the different retrievers based on the search strategy. Ok?  Ah one more thing I'd like to mention right now is that there are a lot of retrievers in Langchen.  There are probably 20, 25, 30 retrievers.  I don't know, there might be more than that.  So obviously it is not possible for me to cover all the retrievers in this video.  But I will cover the most relevant and most useful retrievers for you in this video. Rest I will point you to the right direction.  I will tell you in the documentation where you can read about retrievers.  By going there you can read about whichever retriever you think is useful for you. Ok?  So now let's move on to Wikipedia Retriever.  So first of all we will\"), Document(id='fa5b1fa2-554a-4e1f-9945-03af9f98a060', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2820s', 'start_seconds': 2820, 'start_timestamp': '00:47:00'}, page_content='enter your model here.  Ok?  And in this step we have formed our retriever.  Now suppose our question is what is photosynthesis?  what did we do? Called CompressionRetriever.invoke and passed our query which in turn gave us the results and now we are printing the results. And you can see guys here are our results.  You will notice that even though all of our documents are one paragraph long, the answers we are getting back are very short one sentence answers.  Because only one line exists around photosynthesis in our documents.  And the same line is being extracted and shown to you. Apart from this, you will not see any sentence about Grand Canyon, Basketball etc. here.  Because all this work is being done behind the scenes by the Contextual Compression Retriever.  Ok? So I hope you understood how this particular retriever works.  Now before ending the video I'), Document(id='5924e11e-1fc0-41c5-9a3b-52d184620f08', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\"), Document(id='8b169358-6baa-4bce-a661-3b6355932512', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\"), Document(id='c6a5d955-1ba1-4411-bf85-16376c430421', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1140s', 'start_seconds': 1140, 'start_timestamp': '00:19:00'}, page_content='bring you the top two results in document object format and store it in a result variable.  Ok?  And the rest of the code is the same.  I just ran a loop to print those results.  So you can see I asked for two results.  So since there is only one document about chroma here, it comes on top.  But since then another result had to be given to him.  So next he again selected this document. Ok?  But you get the idea.  Ok ?  Now here I had a doubt which I will share with you.  Maybe you too might be having that doubt.  This doubt may come to your mind that the work that we just did with the help of a retriever, in the previous video, we had got this work done directly from the Vector Store, if you remember. So what I can do is instead of making this retriever, I can write this code directly also. Vector store dot similarity')]\n",
      "\u001b[36;1m\u001b[1;3m[Document(id='06c18baf-0711-421b-a53f-268da9fde7b8', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1320s', 'start_seconds': 1320, 'start_timestamp': '00:22:00'}, page_content=\"show you how to use advanced retrievers with your vector store, which will internally use very advanced search strategies to fetch relevant documents. So guys so far we have seen two retrievers which you can categorize on the basis of the document source that they are using.  Now we will look at some retrievers which you can differentiate on the basis of retrieval mechanism or retrieval strategy.  The first retriever among them that we are going to discuss is named MMR and its full form is Maximum Marginal Relevance.  Now what is this and how does it work?  Before that let me show you a problem many retrievers face.  Let's say you have this document source where you have a total of five documents stored in it.  Now if you pause the video and read these five documents, you will see that the documents here are around climate change,\"), Document(id='7387208d-fc1d-4762-acee-58c6a1e3869c', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2760s', 'start_seconds': 2760, 'start_timestamp': '00:46:00'}, page_content=\"talking about photosynthesis again.  We are completely talking about basketball here. And here we are talking about cinema extras. Ok?  Now what are we doing here ?  First let's create a vector store. And the Vector store belongs to Fyers again. Here we are passing our documents. Passing our embedding models. Now what do we have to do in this step ?  We need to create our own contextual compression retriever. Before you build a Butt Contextual Compression Retriever, there are two things you need to know.  First what will be your base retriever?  So that's our base retriever.  We created a simple similarity search based retriever using the vector store.  Ok?  And second you have to make a compressor.  So what did we do here?  Created a compressor which is basically an LLM.  Ok ?  And we have a class called LLM Chain Extractor. With its help we are making this compressor. Ok?  You can use this code as it is. You just have to\"), Document(id='f429a961-537f-4600-889b-f9c9be84dcfa', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2880s', 'start_seconds': 2880, 'start_timestamp': '00:48:00'}, page_content='would like to discuss one more thing with you that apart from the retrievers that we have read about till now, there are many other retrievers that exist.  Such as Parent Document Retriever, Time Weighted Vector Retriever, Self Query Retriever, OnSumable Retriever, Multi Retriever and so on.  If you want to know more about any of these retrievers or if you need it in your project then you can visit this particular link. I will give it to you in the description of the video. All the Retrievers available in Lang Chen are provided to you here. You can click on any of these and see how that particular retriever works.  You will get sample code and its description all at one place. Obviously it is not possible to cover all these retrievers. Going forward, when we create projects etc., if we need any particular retriever then I will definitely read it to you.  But covering everything did'), Document(id='9535fc07-6c02-477c-afb6-c1fd24cf8e34', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=540s', 'start_seconds': 540, 'start_timestamp': '00:09:00'}, page_content=\"retrievers.  So now what do I do first?  I will give you a little flavour of the different categories based on the data source and then after that I will give you a little flavour of the different retrievers based on the search strategy. Ok?  Ah one more thing I'd like to mention right now is that there are a lot of retrievers in Langchen.  There are probably 20, 25, 30 retrievers.  I don't know, there might be more than that.  So obviously it is not possible for me to cover all the retrievers in this video.  But I will cover the most relevant and most useful retrievers for you in this video. Rest I will point you to the right direction.  I will tell you in the documentation where you can read about retrievers.  By going there you can read about whichever retriever you think is useful for you. Ok?  So now let's move on to Wikipedia Retriever.  So first of all we will\"), Document(id='fa5b1fa2-554a-4e1f-9945-03af9f98a060', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2820s', 'start_seconds': 2820, 'start_timestamp': '00:47:00'}, page_content='enter your model here.  Ok?  And in this step we have formed our retriever.  Now suppose our question is what is photosynthesis?  what did we do? Called CompressionRetriever.invoke and passed our query which in turn gave us the results and now we are printing the results. And you can see guys here are our results.  You will notice that even though all of our documents are one paragraph long, the answers we are getting back are very short one sentence answers.  Because only one line exists around photosynthesis in our documents.  And the same line is being extracted and shown to you. Apart from this, you will not see any sentence about Grand Canyon, Basketball etc. here.  Because all this work is being done behind the scenes by the Contextual Compression Retriever.  Ok? So I hope you understood how this particular retriever works.  Now before ending the video I'), Document(id='5924e11e-1fc0-41c5-9a3b-52d184620f08', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\"), Document(id='8b169358-6baa-4bce-a661-3b6355932512', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\"), Document(id='c6a5d955-1ba1-4411-bf85-16376c430421', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1140s', 'start_seconds': 1140, 'start_timestamp': '00:19:00'}, page_content='bring you the top two results in document object format and store it in a result variable.  Ok?  And the rest of the code is the same.  I just ran a loop to print those results.  So you can see I asked for two results.  So since there is only one document about chroma here, it comes on top.  But since then another result had to be given to him.  So next he again selected this document. Ok?  But you get the idea.  Ok ?  Now here I had a doubt which I will share with you.  Maybe you too might be having that doubt.  This doubt may come to your mind that the work that we just did with the help of a retriever, in the previous video, we had got this work done directly from the Vector Store, if you remember. So what I can do is instead of making this retriever, I can write this code directly also. Vector store dot similarity')]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The video appears to be about retrievers in the context of language models and vector stores. It covers the basics of retrievers, their importance in langchain, and different types of retrievers such as Maximum Marginal Relevance, Contextual Compression Retriever, and others. The video also provides code examples and explanations of how to use these retrievers.\n",
      "\n",
      "Action: retriever_vectorstore_tool\n",
      "Action Input: \"retriever types\"\u001b[0m_______________Retrieved Context from vectorstore_____ [Document(id='ddaf17e0-2c34-4933-9137-434940c3c769', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=420s', 'start_seconds': 420, 'start_timestamp': '00:07:00'}, page_content='most relevant.  And there are many more such retrievers which are categorized on the basis of data source. Like one more is Archive Retriever which goes to this website and scans all the research papers and gives you the relevant results. So I hope you understand that one of the ways to differentiate between different retrievers is what type of data source they are working on.  Ok?  So this is one way to differentiate.  There is one more way.  The second way is that you can also categorize retrievers based on the search strategy of the retriever.  This means that different retrievers use different mechanisms to search for documents. So on the basis of these different mechanisms, we can categorize'), Document(id='030469a5-08f5-4a16-b3e8-63076eaffae5', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=360s', 'start_seconds': 360, 'start_timestamp': '00:06:00'}, page_content=\"can divide the types of retrievers into two categories.   The first category is on the basis of data source. So different retrievers work with different data sources.  Ok?  So on that basis we can categorize retrievers.  Like you will see a retriever whose name is Wikipedia Retriever. Ok?  Now, what is special about this retriever?  That it picks up your query and goes to Wikipedia and searches it. So all the articles on Wikipedia become your data source and this becomes your user's query.  Now based on the user's query you are bringing relevant Wikipedia articles.  Ok?  Second, another type of retriever is based on the data source: vector store based retrievers.  Suppose you have stored your data in vector store and now user query comes and what will this particular retriever do?  Vector will go to the store and find which documents are\"), Document(id='b51df7c4-9a9f-4041-bd40-23a42763a228', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=480s', 'start_seconds': 480, 'start_timestamp': '00:08:00'}, page_content=\"different retrievers.  Like you have a Retriever with MMR Maximum Marginal Relevance which we will read about next.  There is another one called Multi Query Retriever.  There's another one called Contextual Compression Retriever.  Now at this point what are all these retrievers?  I'm not going to tell you.  Going forward I will explain it to you.  But just understand that all these retrievers perform searching in different ways.  So their way of searching is different and hence different types exist.  So in simple words if someone asks you what are the different types of retrievers?  So you just have to think like this that you can create categories in two ways.  One is which data source that retriever is working with. And the second is which strategy he is using for searching. On the basis of these two things you can create different types of\"), Document(id='f429a961-537f-4600-889b-f9c9be84dcfa', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2880s', 'start_seconds': 2880, 'start_timestamp': '00:48:00'}, page_content='would like to discuss one more thing with you that apart from the retrievers that we have read about till now, there are many other retrievers that exist.  Such as Parent Document Retriever, Time Weighted Vector Retriever, Self Query Retriever, OnSumable Retriever, Multi Retriever and so on.  If you want to know more about any of these retrievers or if you need it in your project then you can visit this particular link. I will give it to you in the description of the video. All the Retrievers available in Lang Chen are provided to you here. You can click on any of these and see how that particular retriever works.  You will get sample code and its description all at one place. Obviously it is not possible to cover all these retrievers. Going forward, when we create projects etc., if we need any particular retriever then I will definitely read it to you.  But covering everything did'), Document(id='1ff1b523-c8f8-4df9-9db8-c8c05acef8b8', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=240s', 'start_seconds': 240, 'start_timestamp': '00:04:00'}, page_content=\"retriever is nothing but a function which is taking user's query as input.   It is giving you multiple document objects in the output and in between, what it is doing in its processing is that it is entering a data source and searching it.  It's like a search engine.  Ok?  Which gives you relevant results. One more thing I would like to clarify for you right now is that Langchen does not have just one retriever.  There are multiple retrievers and we will go through all of them in detail shortly but it should already be clear that there is not a single retriever. There are multiple retrievers for different use cases.  Ok?  And point number three, which is the substantive point, is that all the retrievers that you will see in Langchen are runnables.  Just like models, prapts extra.  What does it mean?   This means that you\"), Document(id='8b169358-6baa-4bce-a661-3b6355932512', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\"), Document(id='9535fc07-6c02-477c-afb6-c1fd24cf8e34', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=540s', 'start_seconds': 540, 'start_timestamp': '00:09:00'}, page_content=\"retrievers.  So now what do I do first?  I will give you a little flavour of the different categories based on the data source and then after that I will give you a little flavour of the different retrievers based on the search strategy. Ok?  Ah one more thing I'd like to mention right now is that there are a lot of retrievers in Langchen.  There are probably 20, 25, 30 retrievers.  I don't know, there might be more than that.  So obviously it is not possible for me to cover all the retrievers in this video.  But I will cover the most relevant and most useful retrievers for you in this video. Rest I will point you to the right direction.  I will tell you in the documentation where you can read about retrievers.  By going there you can read about whichever retriever you think is useful for you. Ok?  So now let's move on to Wikipedia Retriever.  So first of all we will\"), Document(id='5924e11e-1fc0-41c5-9a3b-52d184620f08', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\")]\n",
      "\u001b[36;1m\u001b[1;3m[Document(id='ddaf17e0-2c34-4933-9137-434940c3c769', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=420s', 'start_seconds': 420, 'start_timestamp': '00:07:00'}, page_content='most relevant.  And there are many more such retrievers which are categorized on the basis of data source. Like one more is Archive Retriever which goes to this website and scans all the research papers and gives you the relevant results. So I hope you understand that one of the ways to differentiate between different retrievers is what type of data source they are working on.  Ok?  So this is one way to differentiate.  There is one more way.  The second way is that you can also categorize retrievers based on the search strategy of the retriever.  This means that different retrievers use different mechanisms to search for documents. So on the basis of these different mechanisms, we can categorize'), Document(id='030469a5-08f5-4a16-b3e8-63076eaffae5', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=360s', 'start_seconds': 360, 'start_timestamp': '00:06:00'}, page_content=\"can divide the types of retrievers into two categories.   The first category is on the basis of data source. So different retrievers work with different data sources.  Ok?  So on that basis we can categorize retrievers.  Like you will see a retriever whose name is Wikipedia Retriever. Ok?  Now, what is special about this retriever?  That it picks up your query and goes to Wikipedia and searches it. So all the articles on Wikipedia become your data source and this becomes your user's query.  Now based on the user's query you are bringing relevant Wikipedia articles.  Ok?  Second, another type of retriever is based on the data source: vector store based retrievers.  Suppose you have stored your data in vector store and now user query comes and what will this particular retriever do?  Vector will go to the store and find which documents are\"), Document(id='b51df7c4-9a9f-4041-bd40-23a42763a228', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=480s', 'start_seconds': 480, 'start_timestamp': '00:08:00'}, page_content=\"different retrievers.  Like you have a Retriever with MMR Maximum Marginal Relevance which we will read about next.  There is another one called Multi Query Retriever.  There's another one called Contextual Compression Retriever.  Now at this point what are all these retrievers?  I'm not going to tell you.  Going forward I will explain it to you.  But just understand that all these retrievers perform searching in different ways.  So their way of searching is different and hence different types exist.  So in simple words if someone asks you what are the different types of retrievers?  So you just have to think like this that you can create categories in two ways.  One is which data source that retriever is working with. And the second is which strategy he is using for searching. On the basis of these two things you can create different types of\"), Document(id='f429a961-537f-4600-889b-f9c9be84dcfa', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2880s', 'start_seconds': 2880, 'start_timestamp': '00:48:00'}, page_content='would like to discuss one more thing with you that apart from the retrievers that we have read about till now, there are many other retrievers that exist.  Such as Parent Document Retriever, Time Weighted Vector Retriever, Self Query Retriever, OnSumable Retriever, Multi Retriever and so on.  If you want to know more about any of these retrievers or if you need it in your project then you can visit this particular link. I will give it to you in the description of the video. All the Retrievers available in Lang Chen are provided to you here. You can click on any of these and see how that particular retriever works.  You will get sample code and its description all at one place. Obviously it is not possible to cover all these retrievers. Going forward, when we create projects etc., if we need any particular retriever then I will definitely read it to you.  But covering everything did'), Document(id='1ff1b523-c8f8-4df9-9db8-c8c05acef8b8', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=240s', 'start_seconds': 240, 'start_timestamp': '00:04:00'}, page_content=\"retriever is nothing but a function which is taking user's query as input.   It is giving you multiple document objects in the output and in between, what it is doing in its processing is that it is entering a data source and searching it.  It's like a search engine.  Ok?  Which gives you relevant results. One more thing I would like to clarify for you right now is that Langchen does not have just one retriever.  There are multiple retrievers and we will go through all of them in detail shortly but it should already be clear that there is not a single retriever. There are multiple retrievers for different use cases.  Ok?  And point number three, which is the substantive point, is that all the retrievers that you will see in Langchen are runnables.  Just like models, prapts extra.  What does it mean?   This means that you\"), Document(id='8b169358-6baa-4bce-a661-3b6355932512', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\"), Document(id='9535fc07-6c02-477c-afb6-c1fd24cf8e34', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=540s', 'start_seconds': 540, 'start_timestamp': '00:09:00'}, page_content=\"retrievers.  So now what do I do first?  I will give you a little flavour of the different categories based on the data source and then after that I will give you a little flavour of the different retrievers based on the search strategy. Ok?  Ah one more thing I'd like to mention right now is that there are a lot of retrievers in Langchen.  There are probably 20, 25, 30 retrievers.  I don't know, there might be more than that.  So obviously it is not possible for me to cover all the retrievers in this video.  But I will cover the most relevant and most useful retrievers for you in this video. Rest I will point you to the right direction.  I will tell you in the documentation where you can read about retrievers.  By going there you can read about whichever retriever you think is useful for you. Ok?  So now let's move on to Wikipedia Retriever.  So first of all we will\"), Document(id='5924e11e-1fc0-41c5-9a3b-52d184620f08', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\")]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "\n",
      "Final Answer: The video discusses retrievers in the context of language models and vector stores. It covers the basics of retrievers, their importance in langchain, and different types of retrievers such as Maximum Marginal Relevance, Contextual Compression Retriever, and others. The video also provides code examples and explanations of how to use these retrievers. Retriever types can be categorized based on the data source they work with and the search strategy they use. There are many retrievers available in Langchen, including Wikipedia Retriever, Vector Store based retrievers, and others. The video provides a detailed explanation of retrievers and their use cases, and it is an important topic for building RAG-based applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain me in detail the summary of the video ?\"\n",
    "messages = agent_executor.invoke({\"input\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4feccd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video discusses retrievers in the context of language models and vector stores. It covers the basics of retrievers, their importance in langchain, and different types of retrievers such as Maximum Marginal Relevance, Contextual Compression Retriever, and others. The video also provides code examples and explanations of how to use these retrievers. Retriever types can be categorized based on the data source they work with and the search strategy they use. There are many retrievers available in Langchen, including Wikipedia Retriever, Vector Store based retrievers, and others. The video provides a detailed explanation of retrievers and their use cases, and it is an important topic for building RAG-based applications.\n"
     ]
    }
   ],
   "source": [
    "print(messages['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "548742ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________Retrieved Context from vectorstore_____ [Document(id='bdf26d33-c0a0-4a5f-b4a5-2c7aac65d5c1', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=3060s', 'start_seconds': 3060, 'start_timestamp': '00:51:00'}, page_content='application.  Ok?  So with that I will conclude this video.  If you liked the video, please like it.  If you have not subscribed to this channel, please do subscribe.  See you in the next video , bye.'), Document(id='5924e11e-1fc0-41c5-9a3b-52d184620f08', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\"), Document(id='06c18baf-0711-421b-a53f-268da9fde7b8', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1320s', 'start_seconds': 1320, 'start_timestamp': '00:22:00'}, page_content=\"show you how to use advanced retrievers with your vector store, which will internally use very advanced search strategies to fetch relevant documents. So guys so far we have seen two retrievers which you can categorize on the basis of the document source that they are using.  Now we will look at some retrievers which you can differentiate on the basis of retrieval mechanism or retrieval strategy.  The first retriever among them that we are going to discuss is named MMR and its full form is Maximum Marginal Relevance.  Now what is this and how does it work?  Before that let me show you a problem many retrievers face.  Let's say you have this document source where you have a total of five documents stored in it.  Now if you pause the video and read these five documents, you will see that the documents here are around climate change,\"), Document(id='bfd40b71-0d54-4c97-bd54-d984cf4a0d8d', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1080s', 'start_seconds': 1080, 'start_timestamp': '00:18:00'}, page_content='vectors are forming.  And here we have created the collection form as we did in the last video.  Ok?  And we ran it.  Now once your vector store is formed, you can form a retriever with the help of the vector store. So vector store dot edge retriever function is to create a retriever vector store retriever.  Ok? All you have to do here is tell how many relevant results you want back.  So we set the value of K to two and we have formed a retriever object.  Ok? In this step.  What are we doing now?  Writing a query. Like the query is what is chroma used for.  what shall we do now?   We will call the retriever.invoke function and we will pass this query.  Now what will happen behind the scenes?  This retriever will go.  This will convert this query into a vector.   It will perform a semantic search and'), Document(id='68c536f4-0ed6-438f-af06-5ca0bfb47955', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1440s', 'start_seconds': 1440, 'start_timestamp': '00:24:00'}, page_content='requested three results.  Here are your three results.  Document One has arrived.  This one, document two has also come, this one and document three has also come.  Because the relevance of these three was the highest.  Now what is the problem with these three results is that the first two results are saying exactly the same thing about glaciers are melting right and the third thing is talking about deforestation which is showing you a different perspective about climate change.  But the problem is that two out of three things are saying the same thing. What would have happened ideally?  It would have been better if we had shown these results where the first one would have been Document One, we would have fetched it, we would have talked about glacier melting, we would have brought D4 where we would have talked about wildfires, we would have talked about D5 where we would have talked about coastal cities getting submerged, here you are getting more'), Document(id='c6a5d955-1ba1-4411-bf85-16376c430421', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1140s', 'start_seconds': 1140, 'start_timestamp': '00:19:00'}, page_content='bring you the top two results in document object format and store it in a result variable.  Ok?  And the rest of the code is the same.  I just ran a loop to print those results.  So you can see I asked for two results.  So since there is only one document about chroma here, it comes on top.  But since then another result had to be given to him.  So next he again selected this document. Ok?  But you get the idea.  Ok ?  Now here I had a doubt which I will share with you.  Maybe you too might be having that doubt.  This doubt may come to your mind that the work that we just did with the help of a retriever, in the previous video, we had got this work done directly from the Vector Store, if you remember. So what I can do is instead of making this retriever, I can write this code directly also. Vector store dot similarity'), Document(id='8b169358-6baa-4bce-a661-3b6355932512', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\"), Document(id='fa5b1fa2-554a-4e1f-9945-03af9f98a060', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2820s', 'start_seconds': 2820, 'start_timestamp': '00:47:00'}, page_content='enter your model here.  Ok?  And in this step we have formed our retriever.  Now suppose our question is what is photosynthesis?  what did we do? Called CompressionRetriever.invoke and passed our query which in turn gave us the results and now we are printing the results. And you can see guys here are our results.  You will notice that even though all of our documents are one paragraph long, the answers we are getting back are very short one sentence answers.  Because only one line exists around photosynthesis in our documents.  And the same line is being extracted and shown to you. Apart from this, you will not see any sentence about Grand Canyon, Basketball etc. here.  Because all this work is being done behind the scenes by the Contextual Compression Retriever.  Ok? So I hope you understood how this particular retriever works.  Now before ending the video I')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='bdf26d33-c0a0-4a5f-b4a5-2c7aac65d5c1', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=3060s', 'start_seconds': 3060, 'start_timestamp': '00:51:00'}, page_content='application.  Ok?  So with that I will conclude this video.  If you liked the video, please like it.  If you have not subscribed to this channel, please do subscribe.  See you in the next video , bye.'),\n",
       " Document(id='5924e11e-1fc0-41c5-9a3b-52d184620f08', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=120s', 'start_seconds': 120, 'start_timestamp': '00:02:00'}, page_content=\"how we are moving forward with this playlist. Now let's focus on today's video, which is on retrievers. Retrievers are very important in langche.  So we will cover this in great detail in today's video.  First of all, we will start with this discussion that what are retrievers?  So in very simple words, if you read this first line, it is written here that a retriever is a component in the language that fetches relevant documents from a data source in response to a user's query.  Ok?  If you focus on this diagram, you will understand things better visually. So what happens is that you have a data source where all your data is stored.  Ok ?  All the data related to anything is stupid.  Now this data source can be anything.  It could be a vector store and it could be some API or something.\"),\n",
       " Document(id='06c18baf-0711-421b-a53f-268da9fde7b8', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1320s', 'start_seconds': 1320, 'start_timestamp': '00:22:00'}, page_content=\"show you how to use advanced retrievers with your vector store, which will internally use very advanced search strategies to fetch relevant documents. So guys so far we have seen two retrievers which you can categorize on the basis of the document source that they are using.  Now we will look at some retrievers which you can differentiate on the basis of retrieval mechanism or retrieval strategy.  The first retriever among them that we are going to discuss is named MMR and its full form is Maximum Marginal Relevance.  Now what is this and how does it work?  Before that let me show you a problem many retrievers face.  Let's say you have this document source where you have a total of five documents stored in it.  Now if you pause the video and read these five documents, you will see that the documents here are around climate change,\"),\n",
       " Document(id='bfd40b71-0d54-4c97-bd54-d984cf4a0d8d', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1080s', 'start_seconds': 1080, 'start_timestamp': '00:18:00'}, page_content='vectors are forming.  And here we have created the collection form as we did in the last video.  Ok?  And we ran it.  Now once your vector store is formed, you can form a retriever with the help of the vector store. So vector store dot edge retriever function is to create a retriever vector store retriever.  Ok? All you have to do here is tell how many relevant results you want back.  So we set the value of K to two and we have formed a retriever object.  Ok? In this step.  What are we doing now?  Writing a query. Like the query is what is chroma used for.  what shall we do now?   We will call the retriever.invoke function and we will pass this query.  Now what will happen behind the scenes?  This retriever will go.  This will convert this query into a vector.   It will perform a semantic search and'),\n",
       " Document(id='68c536f4-0ed6-438f-af06-5ca0bfb47955', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1440s', 'start_seconds': 1440, 'start_timestamp': '00:24:00'}, page_content='requested three results.  Here are your three results.  Document One has arrived.  This one, document two has also come, this one and document three has also come.  Because the relevance of these three was the highest.  Now what is the problem with these three results is that the first two results are saying exactly the same thing about glaciers are melting right and the third thing is talking about deforestation which is showing you a different perspective about climate change.  But the problem is that two out of three things are saying the same thing. What would have happened ideally?  It would have been better if we had shown these results where the first one would have been Document One, we would have fetched it, we would have talked about glacier melting, we would have brought D4 where we would have talked about wildfires, we would have talked about D5 where we would have talked about coastal cities getting submerged, here you are getting more'),\n",
       " Document(id='c6a5d955-1ba1-4411-bf85-16376c430421', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=1140s', 'start_seconds': 1140, 'start_timestamp': '00:19:00'}, page_content='bring you the top two results in document object format and store it in a result variable.  Ok?  And the rest of the code is the same.  I just ran a loop to print those results.  So you can see I asked for two results.  So since there is only one document about chroma here, it comes on top.  But since then another result had to be given to him.  So next he again selected this document. Ok?  But you get the idea.  Ok ?  Now here I had a doubt which I will share with you.  Maybe you too might be having that doubt.  This doubt may come to your mind that the work that we just did with the help of a retriever, in the previous video, we had got this work done directly from the Vector Store, if you remember. So what I can do is instead of making this retriever, I can write this code directly also. Vector store dot similarity'),\n",
       " Document(id='8b169358-6baa-4bce-a661-3b6355932512', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"Hi guys, my name is Nitesh and welcome to my YouTube channel.  In this video also we will continue our lang chain playlist. And the topic of today's video is retrievers which is a very important topic.  If you talk about rag.  If you want to build a RAG based application then retriever is a very important component.  In fact, in the future when you make some advanced rag systems, you will work with different types of retrievers there, so in that sense this particular video is very important. And I would like you to watch this video end to end.  So in today's video I will not only explain to you what are retrievers?  What do they need?  But at the same time I will also tell you about different types of retrievers and will show you the code.  Ok?  So ya let's start the video.  So guys, before we start the video, I would like to give you a quick recap of what we have been doing in this playlist for the last three-four videos.\"),\n",
       " Document(id='fa5b1fa2-554a-4e1f-9945-03af9f98a060', metadata={'source': 'https://www.youtube.com/watch?v=pJdMxwXBsk0&t=2820s', 'start_seconds': 2820, 'start_timestamp': '00:47:00'}, page_content='enter your model here.  Ok?  And in this step we have formed our retriever.  Now suppose our question is what is photosynthesis?  what did we do? Called CompressionRetriever.invoke and passed our query which in turn gave us the results and now we are printing the results. And you can see guys here are our results.  You will notice that even though all of our documents are one paragraph long, the answers we are getting back are very short one sentence answers.  Because only one line exists around photosynthesis in our documents.  And the same line is being extracted and shown to you. Apart from this, you will not see any sentence about Grand Canyon, Basketball etc. here.  Because all this work is being done behind the scenes by the Contextual Compression Retriever.  Ok? So I hope you understood how this particular retriever works.  Now before ending the video I')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_vectorstore_tool.invoke(\"Explain me in detail the summary of the video ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a3322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2d17ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144d2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
